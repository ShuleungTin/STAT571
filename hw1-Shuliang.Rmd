---
title: "STAT 471/571/701 Modern Data Mining, HW 1"
author:
- Group Member 1
- Group Member 2
- Group Member 3
date: 'Due: 11:59PM,  September 15, 2019'
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, readxl, magrittr, dplyr, ggplot2, latex2exp)
```


\pagebreak

# Overview

This is a fast-paced course that covers a lot of material. There will be a large amount of references. You may need to do your own research to fill in the gaps in between lectures and homework/projects. It is impossible to learn data science without getting your hands dirty. Please budget your time evenly. Last-minute work ethic will not work for this course. 


## Objectives

- Get familiar with `R-studio` and `RMarkdown`
- Learn data science essentials 
    - gather data
    - clean data
    - summarize data 
    - display data
    - conclusion
- Packages
    - `lm()`
    - `dplyr`
    - `ggplot`
- Methods
    - normality
    - sampling distribution
    - confidence intervals
    - $p$-values
    - linear models
    

##  Instructions

- **Homework assignments can be done in a group consisting of up to three members**. Please find your group members as soon as possible and register your group on our Canvas site.

- **All work submitted should be completed in the R markdown format.** You can find a cheat sheet for R Markdown [here](https://github.com/rstudio/cheatsheets/raw/master/rmarkdown-2.0.pdf). For those who have never used it before, we urge you to start this homework as soon as possible. 

- **Submit the following files, one submission for each group:**  (1) Rmd file, (2) a compiled PDF or HTML version, and (3) all necessary data files. You can directly edit this file to add your answers. If you intend to work on the problems separately within your group, compile your answers into one Rmd file before submitting. We encourage that you at least attempt each problem by yourself before working with your teammates. Additionally, ensure that you can 'knit' or compile your Rmd file. It is also likely that you need to configure Rstudio to properly convert files to PDF. [**These instructions**](http://kbroman.org/knitr_knutshell/pages/latex.html#converting-knitrlatex-to-pdf) should be helpful.

- In general, be as concise as possible while giving a fully complete answer. All necessary datasets are available in the "Data" folder or this homework folder on Canvas. Make sure to document your code with comments so the teaching fellows can follow along. R Markdown is particularly useful because it follows a 'stream of consciousness' approach: as you write code in a code chunk, make sure to explain what you are doing outside of the chunk. 

- A few good submissions will be used as sample solutions. When those are released, make sure to compare your answers and understand the solutions.


# Review materials

- Study both R-tutorials
- Study lecture 1: EDA/Simple regression
- Study lecture 2: Multiple regression


# Case study: Women in Science

Are women underrepresented in science in general? How does gender relate to the type of educational degree pursued? Does number of higher degrees increase over the years? In an attempt to answer these questions, we assembled a data set (`WomenData_06_16.xlsx`) from [NSF](https://ncses.nsf.gov/pubs/nsf19304/digest/field-of-degree-women) about various degrees granted in the U.S. from 2006 to 2016. It contains the following variables: Field (Non-science-engineering (`Non-S&E`) and sciences (`Computer sciences`, `Mathematics and statistics`, etc.)), Degree (`BS`, `MS`, `PhD`), Sex (`M`, `F`), Number of degrees granted, and Year.

Our goal is to answer the above questions only through EDA (Exploratory Data Analyses) without formal testing.


## Load the data 

Notice the data came in as an excel file. We need to use a package `readxl` and the function `read_excel()` to read the data `WomenData_06_16.xlsx` into R. 

1. Read the data into R.
```{r, echo = FALSE, warning = FALSE}
wsci <- read_excel('WomenData_06_16.xlsx')
```
2. Clean the names of each variables.
```{r, echo = FALSE, warning = FALSE}
names(wsci)[1] <- "Field"
names(wsci)[5] <- "Number"
```
3. Set the variable natures properly. 
```{r, echo = FALSE, warning = FALSE}
wsci$Field <- as.factor(wsci$Field)
wsci$Degree <- as.factor(wsci$Degree)
wsci$Sex <- as.factor(wsci$Sex)
```
4. Provide a quick summary of the data set. 
```{r, echo = FALSE, warning = FALSE}
summary(wsci)
```
5. Write a summary describing the data set provided here. 


To help out, we have included some codes here as references. You should make this your own chunks filled with texts going through each items listed above. Make sure to hide the unnecessary outputs/code etc. 
```{r data wrangling, echo = TRUE, warning = FALSE}
# For the demonstration purpose, we show this R-chunk by taking echo=TRUE
# In your final report you should hide all the R-chunks to keep your report flowing well.
wsci <- read_excel("WomenData_06_16.xlsx")
# str(wsci)

# base R
names(wsci)[1] <- "Field"
names(wsci)[5] <- "Number"
# names(wsci)
wsci$Field  <-   as.factor(wsci$Field)
wsci$Degree <- as.factor(wsci$Degree)
wsci$Sex <- as.factor(wsci$Sex)

summary(wsci)

# dplyr way
# wsci %<>% 
#   rename(Field = "Field and sex",
#          Number = "Degrees Awarded") %>%
#   mutate(Field = as.factor(Field),
#          Degree = as.factor(Degree),
#          Sex = as.factor(Sex))
```

## EDA

### Focus on BS degree and in 2015

Is there evidence that more males are in science related fields vs `Non-S&E`? Provide summary statistics and a plot which shows the number of people by gender and by field. Write a brief summary to describe your findings.

```{r, echo = FALSE}
wsci %>%
  filter(Degree == 'BS' & Year == 2015) %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  {. ->> summary.SE} %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Degrees granted by S&E vs non-S&E by gender")
```
```{r, echo=FALSE}
summary.SE.male <- summary.SE %>%
  filter(Sex=='Male')
summary.SE.male
```

### In 2015

Describe the number of people by type of degree, field, and gender. Do you see any evidence of gender effects over types of degree? Again, provide graphs to summarize your findings.
```{r, echo=FALSE}
wsci %>%
  filter(Year == 2015) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust=1)) +
  ggtitle("Degrees granted across fields by degree and gender") 
```
### Time effects

In this last portion of the EDA, we ask you to provide evidence graphically: Do the number of  degrees change by gender, field, and time? 
```{r, echo=FALSE}
wsci %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Year~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust=1)) +
  ggtitle("Degrees granted across fields by gender and time") 
```
### Women in Data Science

Finally, is there evidence showing that women are underrepresented in data science? Data science is an interdisciplinary field of computer science, math, and statistics. You may include year and/or degree.
```{r}
wsci %>%
  filter(Field %in% c('Computer sciences', 'Mathematics and statistics')) %>%
  group_by(Degree, Sex, Year) %>%
  summarise(DS_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = DS_number, fill = Sex)) +
  geom_bar(stat='identity', position='dodge') +
  facet_grid(Degree~., scales = 'free_y') +
  ggtitle("Degrees granted in Data Science across year by degree and gender")
```
## Final brief report

Summarize your findings focusing on answering the questions regarding if we see consistent patterns that more males pursue science-related fields. Any concerns with the data set? How could we improve on the study?

## Appendix

Here are several sample codes for your reference.

```{r eval = FALSE, echo = TRUE}
wsci %>%  # to get the average number of ppl by gender
  group_by(Field, Sex) %>%
  summarise(deg = mean(Number))

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 60)) +
  ggtitle("Degrees granted by S&E vs non-S&E by gender")

wsci %>%
  filter(Year == 2007) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ggtitle("Degrees granted across fields by degree and gender") 

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  ggtitle("Female proportion in SE/non-SE across year")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year, Degree) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  facet_grid(~Degree)+
  ggtitle("Female proportion in SE/non-SE across year by degree")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted by sex, degree and SE")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted proption by sex across degree and SE")


wsci %>%
  filter(Field %in% c("Computer sciences", "Mathematics and statistics")) %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proption by sex across degree and SE")


wsci %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proption by sex across degree and SE")
```
```{r}
remove(list=ls())
```

# Simple Regression
    
## Linear model through simulations

This exercise is designed to help you understand the linear model using simulations. In this exercise, we will generate $(x_i, y_i)$ pairs so that all linear model assumptions are met.

Presume that $\mathbf{x}$ and $\mathbf{y}$ are linearly related with a normal error $\boldsymbol{\varepsilon}$ , such that $\mathbf{y} = 1 + 1.2\mathbf{x} + \boldsymbol{\varepsilon}$. The standard deviation of the error $\varepsilon_i$ is $\sigma = 2$. 

We can create a sample input vector ($n = 40$) for $\mathbf{x}$ with the following code:

```{r, echo = TRUE}
# Generates a vector of size 40 with equally spaced values between 0 and 1, inclusive
x <- seq(0, 1, length = 40)
```


### Generate data

Create a corresponding output vector for $\mathbf{y}$ according to the equation given above. Use `set.seed(1)`. Then, create a scatterplot with $(x_i, y_i)$ pairs. Base R plotting is acceptable, but if you can, please attempt to use `ggplot2` to create the plot. Make sure to have clear labels and sensible titles on your plots.

```{r, fig.width=5, echo=TRUE}
set.seed(1)
y <- 1 + 1.2*x + rnorm(40, sd=2)
df <- data.frame(x, y)
ggplot(df, aes(x = x, y = y))+
  geom_point()+
  labs(title = TeX("Scatterplot of $(x_i, y_i)$ pairs"), x='x', y='y')
```

### Understand the model
i. Find the LS estimates of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$, using the `lm()` function. What are the true values of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$? Do the estimates look to be good? 

Yuhan: Here are two methods. If we simply calculate the deviation percentage, is around 30%, which is pretty bad. But if we do t-test, we cannot reject H0: beta0 is 1 and beta1 is 1.2. What do you think?
```{r, echo=TRUE}
lse <- lm(y~x, data = df)
beta_0 <- lse$coefficients[1]
beta_1 <- lse$coefficients[2]
s <- summary(lse)
# deviation_beta_0 <- abs(beta_0-1)/1
# deviation_beta_1 <- abs(beta_1-1.2)/1.2
t_beta0 <- abs(beta_0-1) / s$coefficients[1, 2]
t_beta1 <- abs(beta_1-1.2) / s$coefficients[2, 2]
p_beta0 <- pt(t_beta0, df = 38)
p_beta1 <- pt(t_beta1, df = 38)
cat("p value of beta_0 is: ", p_beta0, "\n")
cat("p value of beta_1 is: ", p_beta1, "\n")
```
ii. What is your RSE for this linear model fit? Is it close to $\sigma = 2$? 
```{r, echo=TRUE}
sig <- summary(lse)$sigma
deviation_portion <- abs(sig-2)/2
deviation_portion
```
ii. What is the 95% confidence interval for $\boldsymbol{\beta}_1$? Does this confidence interval capture the true $\boldsymbol{\beta}_1$?

The 95% confidence interval captured the true value of $\boldsymbol{\beta}_1$.
```{r, echo=TRUE}
confint(lse)[c(2,4)]
```
iii. Overlay the LS estimates and the true lines of the mean function onto a copy of the scatterplot you made above.

```{r, echo=TRUE}
ggplot(df, aes(x=x, y=y)) +
  geom_point() +
  geom_smooth(method = 'lm', color="red") +
  geom_abline(intercept = 1, slope = 1.2, color="blue") +
  labs(title = TeX("Scatterplot of $(x_i, y_i)$ pairs"), x='x', y='y')
```

### diagnoses

i. Provide residual plot where fitted $\mathbf{y}$-values are on the x-axis and residuals are on the y-axis. 
```{r, echo=TRUE}
plot(lse$fitted, lse$residuals, pch=16, main = "residual plot", xlab = "fitted y values", ylab = "residuals")
abline(h=0, col="red")
```
ii. Provide a normal QQ plot of the residuals.
```{r, echo=TRUE}
qqnorm(lse$residuals)
qqline(lse$residuals, col = "red")
```
iii. Comment on how well the model assumptions are met for the sample you used. 

Not perfectly met. First, the residual points are neither symmetric w.r.t fitted y=0, nor evenly distributed within a band. Second, the qqplot shows the residuals are not normally distributed because of fat left tail.

### Understand sampling distribution and confidence intervals

This part aims to help you understand the notion of sampling statistics and confidence intervals. Let's concentrate on estimating the slope only.  

Generate 100 samples of size $n = 40$, and estimate the slope coefficient from each sample. We include some sample code below, which should guide you in setting up the simulation. Note: this code is easier to follow but suboptimal; see the appendix for a more optimal R-like way to run this simulation.
```{r, echo = TRUE}
# Inializing variables. Note b_1, upper_ci, lower_ci are vectors
x <- seq(0, 1, length = 40) 
n_sim <- 100              # number of simulations
b1 <- 0                   # n_sim many LS estimates of beta_1 (=1.2). Initialize to 0 for now
upper_ci <- 0             # upper bound for beta_1. Initialize to 0 for now.
lower_ci <- 0             # lower bound for beta_1. Initialize to 0 for now.
t_star <- qt(0.975, 38)   # Food for thought: why 38 instead of 40? What is t_star?

# Perform the simulation
for (i in 1:n_sim){
  y <- 1 + 1.2 * x + rnorm(40, sd = 2)
  lse <- lm(y ~ x)
  lse_output <- summary(lse)$coefficients
  se <- lse_output[2, 2]
  b1[i] <- lse_output[2, 1]
  upper_ci[i] <- b1[i] + t_star * se
  lower_ci[i] <- b1[i] - t_star * se
}
results <- as.data.frame(cbind(se, b1, upper_ci, lower_ci))

# remove unecessary variables from our workspace
rm(se, b1, x, n_sim, t_star, lse, lse_output) 
```

i. Summarize the LS estimates of $\boldsymbol{\beta}_1$ (stored in `results$b1`). Does the sampling distribution agree with theory?

Confused. Since we don't set seed, sometimes mean is close, sometimes it is far away from 1.2.
```{r, echo=TRUE}
summary(results$b1)
```
ii.  How many of your 95% confidence intervals capture the true $\boldsymbol{\beta}_1$? Display your confidence intervals graphically. 

Yes, almost 95% intervals contain the true value of $\boldsymbol{\beta}_1$.
```{r, echo=TRUE}
x <- 1:100
df <- data.frame(x, upper_ci, lower_ci)
ggplot(df, aes(x=x, ymin=lower_ci, ymax=upper_ci)) +
  geom_linerange() +
  geom_hline(yintercept=1.2, col="red") +
  labs(title="Visualization of confidence intervals", x="index", y="y")
```

## Major League Baseball

This question is about Major League Baseball (MLB) and team payrolls. Guiding questions: how do salaries paid to players affect team wins? How could we model win propensity?

We have put together a dataset consisting of the winning records and the payroll data of all 30 MLB teams from 1998 to 2014. There are 54 variables in the dataset, including:

- `payroll`: total team payroll (in $billions) over the 17-year period 
- `avgwin`: the aggregated win percentage over the 17-year period
- winning percentage and payroll (in $millions) for each team are also broken down for each year. 

The data is stored as `MLPayData_Total.csv` on Canvas.

```{r, echo=TRUE}
salary <- read.csv("MLPayData_Total.csv")
```

### Exploratory questions

For each of the following questions, there is a `dplyr` solution that you should try to answer with.

i. Which five teams spent the most money in total between years 2000 and 2004, inclusive?
```{r, echo=TRUE}
salary %>%
  mutate(total = select(., p2000:p2004) %>% rowSums()) %>%
  arrange(desc(total)) %>%
  filter(row_number() <= 5) %>%
  select(Team.name.2014)
```
ii. Between 1999 and 2000, inclusive, which team(s) "improved" the most? That is, had the biggest percentage gain in wins?
```{r, echo=TRUE}
salary %>%
  mutate(improvement = X2000.pct-X1999.pct) %>%
  arrange(desc(improvement)) %>%
  filter(improvement == max(improvement)) %>%
  select(Team.name.2014)
```
iii. Using `ggplot`, pick a single year, and plot the number of games won vs. `payroll` for that year (`payroll` on x-axis). You may use any 'geom' that makes sense, such as a scatterpoint or a label with the point's corresponding team name.

```{r, echo=TRUE}
salary %>%
  ggplot(aes(x=p2014, y=X2014)) +
  geom_point() +
  labs(title="payroll vs games-won in 2014", x="payroll", y="games-won")
```


### Effect of payroll

For a given year, is `payroll` a significant variable in predicting the winning percentage of that year? Choose a single year and run a regression to examine this. You may try this for a few different years. You can do this programmatically (i.e., for every year) if you are interested, but it is not required.

We can see, it depends on the year we picked. If we assume $\alpha$ = 0.01, in 2012 and 2014, 'payroll' is not significant. But in 1999, 2004 and 2009, we cannot reject 'payroll' is significant.
```{r, echo=TRUE}
r2014 <- lm(X2014.pct~p2014, data=salary)
p2014 <- summary(r2014)$coefficients[8]
r2012 <- lm(X2012.pct~p2012, data=salary)
p2012 <- summary(r2012)$coefficients[8]
r2009 <- lm(X2009.pct~p2009, data=salary)
p2009 <- summary(r2009)$coefficients[8]
r2004 <- lm(X2004.pct~p2004, data=salary)
p2004 <- summary(r2004)$coefficients[8]
r1999 <- lm(X1999.pct~p1999, data=salary)
p1999 <- summary(r1999)$coefficients[8]
cat('p value of beta1 in 2014 is: ', p2014, "\n")
cat('p value of beta1 in 2012 is: ', p2012, "\n")
cat('p value of beta1 in 2009 is: ', p2009, "\n")
cat('p value of beta1 in 2004 is: ', p2004, "\n")
cat('p value of beta1 in 1999 is: ', p1999, "\n")
```


### Reverse regression

With the aggregated information, use regression to analyze total payroll and overall winning percentage. Run appropriate model(s) to answer the following questions:

i. In this analysis, do the [Boston Red Sox](http://darkroom.baltimoresun.com/wp-content/uploads/2013/10/SP.BOSTON28P2.jpg) perform reasonably well given their total amount spent on payroll? [Use a 95% interval.]

The avgwin of Boston Red Sox is 0.549 and is within 95% prediction interval (0.485, 0.602), hence its performance is reasonable.
```{r, echo=TRUE}
pwp <- lm(avgwin~payroll, data = salary)
new <- data.frame(payroll = c(1.972))
PI <- predict(pwp, new, interval = "prediction", se.fit = TRUE)
PI
```
ii. Given their winning percentage, how much would you have expected the Oakland A's to have spent on total payroll? (Use a 95% interval.)

The 95% interval of Oakland A's payroll is (0.952, 2.27).
```{r, echo=TRUE}
wpp <- lm(payroll~avgwin, data = salary)
newdf <- data.frame(avgwin = c(0.545))
PI <- predict(wpp, newdf, interval = "prediction", se.fit = TRUE)
PI
```

```{r}
remove(list=ls())
```