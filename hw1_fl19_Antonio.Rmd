---
title: "STAT 471/571/701 Modern Data Mining, HW 1"
author:
- Group Member 1
- Group Member 2
- Group Member 3
date: 'Due: 11:59PM,  September 15, 2019'
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
#chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(echo = FALSE, results = "hide", fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, readxl, magrittr, dplyr, ggplot2)
```


\pagebreak

# Overview

This is a fast-paced course that covers a lot of material. There will be a large amount of references. You may need to do your own research to fill in the gaps in between lectures and homework/projects. It is impossible to learn data science without getting your hands dirty. Please budget your time evenly. Last-minute work ethic will not work for this course. 


## Objectives

- Get familiar with `R-studio` and `RMarkdown`
- Learn data science essentials 
    - gather data
    - clean data
    - summarize data 
    - display data
    - conclusion
- Packages
    - `lm()`
    - `dplyr`
    - `ggplot`
- Methods
    - normality
    - sampling distribution
    - confidence intervals
    - $p$-values
    - linear models
    

##  Instructions

- **Homework assignments can be done in a group consisting of up to three members**. Please find your group members as soon as possible and register your group on our Canvas site.

- **All work submitted should be completed in the R markdown format.** You can find a cheat sheet for R Markdown [here](https://github.com/rstudio/cheatsheets/raw/master/rmarkdown-2.0.pdf). For those who have never used it before, we urge you to start this homework as soon as possible. 

- **Submit the following files, one submission for each group:**  (1) Rmd file, (2) a compiled PDF or HTML version, and (3) all necessary data files. You can directly edit this file to add your answers. If you intend to work on the problems separately within your group, compile your answers into one Rmd file before submitting. We encourage that you at least attempt each problem by yourself before working with your teammates. Additionally, ensure that you can 'knit' or compile your Rmd file. It is also likely that you need to configure Rstudio to properly convert files to PDF. [**These instructions**](http://kbroman.org/knitr_knutshell/pages/latex.html#converting-knitrlatex-to-pdf) should be helpful.

- In general, be as concise as possible while giving a fully complete answer. All necessary datasets are available in the "Data" folder or this homework folder on Canvas. Make sure to document your code with comments so the teaching fellows can follow along. R Markdown is particularly useful because it follows a 'stream of consciousness' approach: as you write code in a code chunk, make sure to explain what you are doing outside of the chunk. 

- A few good submissions will be used as sample solutions. When those are released, make sure to compare your answers and understand the solutions.


# Review materials

- Study both R-tutorials
- Study lecture 1: EDA/Simple regression
- Study lecture 2: Multiple regression


# Case study: Women in Science

Are women underrepresented in science in general? How does gender relate to the type of educational degree pursued? Does number of higher degrees increase over the years? In an attempt to answer these questions, we assembled a data set (`WomenData_06_16.xlsx`) from [NSF](https://ncses.nsf.gov/pubs/nsf19304/digest/field-of-degree-women) about various degrees granted in the U.S. from 2006 to 2016. It contains the following variables: Field (Non-science-engineering (`Non-S&E`) and sciences (`Computer sciences`, `Mathematics and statistics`, etc.)), Degree (`BS`, `MS`, `PhD`), Sex (`M`, `F`), Number of degrees granted, and Year.

Our goal is to answer the above questions only through EDA (Exploratory Data Analyses) without formal testing.


## Load the data 

Notice the data came in as an excel file. We need to use a package `readxl` and the function `read_excel()` to read the data `WomenData_06_16.xlsx` into R. 

1. Read the data into R.
2. Clean the names of each variables.
3. Set the variable natures properly. 
4. Provide a quick summary of the data set. 
5. Write a summary describing the data set provided here. 


To help out, we have included some codes here as references. You should make this your own chunks filled with texts going through each items listed above. Make sure to hide the unnecessary outputs/code etc. 
```{r data wrangling, echo = TRUE, warning = FALSE}
# For the demonstration purpose, we show this R-chunk by taking echo=TRUE
# In your final report you should hide all the R-chunks to keep your report flowing well.
wsci <- read_excel("WomenData_06_16.xlsx")
# str(wsci)

# base R
names(wsci)[1] <- "Field"
names(wsci)[5] <- "Number"
# names(wsci)
wsci$Field  <-   as.factor(wsci$Field)
wsci$Degree <- as.factor(wsci$Degree)
wsci$Sex <- as.factor(wsci$Sex)
# summary(wsci)

# dplyr way
# wsci %<>% 
#   rename(Field = "Field and sex",
#          Number = "Degrees Awarded") %>%
#   mutate(Field = as.factor(Field),
#          Degree = as.factor(Degree),
#          Sex = as.factor(Sex))
```

## EDA

### Focus on BS degree and in 2015

Is there evidence that more males are in science related fields vs `Non-S&E`? Provide summary statistics and a plot which shows the number of people by gender and by field. Write a brief summary to describe your findings.

### In 2015

Describe the number of people by type of degree, field, and gender. Do you see any evidence of gender effects over types of degree? Again, provide graphs to summarize your findings.

### Time effects

In this last portion of the EDA, we ask you to provide evidence graphically: Do the number of  degrees change by gender, field, and time? 

### Women in Data Science

Finally, is there evidence showing that women are underrepresented in data science? Data science is an interdisciplinary field of computer science, math, and statistics. You may include year and/or degree.

## Final brief report

Summarize your findings focusing on answering the questions regarding if we see consistent patterns that more males pursue science-related fields. Any concerns with the data set? How could we improve on the study?

## Appendix

Here are several sample codes for your reference.

```{r eval = FALSE, echo = TRUE}
wsci %>%  # to get the average number of ppl by gender
  group_by(Field, Sex) %>%
  summarise(deg = mean(Number))

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 60)) +
  ggtitle("Degrees granted by S&E vs non-S&E by gender")

wsci %>%
  filter(Year == 2007) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ggtitle("Degrees granted across fields by degree and gender") 

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  ggtitle("Female proportion in SE/non-SE across year")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year, Degree) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  facet_grid(~Degree)+
  ggtitle("Female proportion in SE/non-SE across year by degree")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted by sex, degree and SE")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted proption by sex across degree and SE")


wsci %>%
  filter(Field %in% c("Computer sciences", "Mathematics and statistics")) %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proption by sex across degree and SE")


wsci %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proption by sex across degree and SE")
```


# Simple Regression
    
## Linear model through simulations

This exercise is designed to help you understand the linear model using simulations. In this exercise, we will generate $(x_i, y_i)$ pairs so that all linear model assumptions are met.

Presume that $\mathbf{x}$ and $\mathbf{y}$ are linearly related with a normal error $\boldsymbol{\varepsilon}$ , such that $\mathbf{y} = 1 + 1.2\mathbf{x} + \boldsymbol{\varepsilon}$. The standard deviation of the error $\varepsilon_i$ is $\sigma = 2$. 

We can create a sample input vector ($n = 40$) for $\mathbf{x}$ with the following code:

```{r, eval = F, echo = TRUE}
# Generates a vector of size 40 with equally spaced values between 0 and 1, inclusive
x <- seq(0, 1, length = 40)
```


### Generate data

Create a corresponding output vector for $\mathbf{y}$ according to the equation given above. Use `set.seed(1)`. Then, create a scatterplot with $(x_i, y_i)$ pairs. Base R plotting is acceptable, but if you can, please attempt to use `ggplot2` to create the plot. Make sure to have clear labels and sensible titles on your plots.

```{r}
# TODO
```

### Understand the model
i. Find the LS estimates of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$, using the `lm()` function. What are the true values of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$? Do the estimates look to be good? 

ii. What is your RSE for this linear model fit? Is it close to $\sigma = 2$? 

ii. What is the 95% confidence interval for $\boldsymbol{\beta}_1$? Does this confidence interval capture the true $\boldsymbol{\beta}_1$?

iii. Overlay the LS estimates and the true lines of the mean function onto a copy of the scatterplot you made above.

```{r}
# TODO
```

### diagnoses

i. Provide residual plot where fitted $\mathbf{y}$-values are on the x-axis and residuals are on the y-axis. 

ii. Provide a normal QQ plot of the residuals.

iii. Comment on how well the model assumptions are met for the sample you used. 


```{r}
# TODO
```


### Understand sampling distribution and confidence intervals

This part aims to help you understand the notion of sampling statistics and confidence intervals. Let's concentrate on estimating the slope only.  

Generate 100 samples of size $n = 40$, and estimate the slope coefficient from each sample. We include some sample code below, which should guide you in setting up the simulation. Note: this code is easier to follow but suboptimal; see the appendix for a more optimal R-like way to run this simulation.
```{r, eval = F, echo = TRUE}
# Inializing variables. Note b_1, upper_ci, lower_ci are vectors
x <- seq(0, 1, length = 40) 
n_sim <- 100              # number of simulations
b1 <- 0                   # n_sim many LS estimates of beta_1 (=1.2). Initialize to 0 for now
upper_ci <- 0             # upper bound for beta_1. Initialize to 0 for now.
lower_ci <- 0             # lower bound for beta_1. Initialize to 0 for now.
t_star <- qt(0.975, 38)   # Food for thought: why 38 instead of 40? What is t_star?

# Perform the simulation
for (i in 1:n_sim){I l
  y <- 1 + 1.2 * x + rnorm(40, sd = 2)
  lse <- lm(y ~ x)
  lse_output <- summary(lse)$coefficients
  se <- lse_output[2, 2]
  b1[i] <- lse_output[2, 1]
  upper_ci[i] <- b1[i] + t_star * se
  lower_ci[i] <- b1[i] - t_star * se
}
results <- as.data.frame(cbind(se, b1, upper_ci, lower_ci))

# remove unecessary variables from our workspace
rm(se, b1, upper_ci, lower_ci, x, n_sim, b1, t_star, lse, lse_out) 
```

i. Summarize the LS estimates of $\boldsymbol{\beta}_1$ (stored in `results$b1`). Does the sampling distribution agree with theory? 

ii.  How many of your 95% confidence intervals capture the true $\boldsymbol{\beta}_1$? Display your confidence intervals graphically. 


```{r}
# TODO
```


## Major League Baseball

This question is about Major League Baseball (MLB) and team payrolls. Guiding questions: how do salaries paid to players affect team wins? How could we model win propensity?

We have put together a dataset consisting of the winning records and the payroll data of all 30 MLB teams from 1998 to 2014. There are 54 variables in the dataset, including:

- `payroll`: total team payroll (in $billions) over the 17-year period 
- `avgwin`: the aggregated win percentage over the 17-year period
- winning percentage and payroll (in $millions) for each team are also broken down for each year. 

The data is stored as `MLPayData_Total.csv` on Canvas.

```{r}
# TODO
# salary <- ... read in data
```

### Exploratory questions

For each of the following questions, there is a `dplyr` solution that you should try to answer with.

i. Which five teams spent the most money in total between years 2000 and 2004, inclusive?

ii. Between 1999 and 2000, inclusive, which team(s) "improved" the most? That is, had the biggest percentage gain in wins?

iii. Using `ggplot`, pick a single year, and plot the number of games won vs. `payroll` for that year (`payroll` on x-axis). You may use any 'geom' that makes sense, such as a scatterpoint or a label with the point's corresponding team name.

```{r}
# TODO
```


### Effect of payroll

For a given year, is `payroll` a significant variable in predicting the winning percentage of that year? Choose a single year and run a regression to examine this. You may try this for a few different years. You can do this programmatically (i.e., for every year) if you are interested, but it is not required.

```{r}
# TODO
```


### Reverse regression

With the aggregated information, use regression to analyze total payroll and overall winning percentage. Run appropriate model(s) to answer the following questions:

i. In this analysis, do the [Boston Red Sox](http://darkroom.baltimoresun.com/wp-content/uploads/2013/10/SP.BOSTON28P2.jpg) perform reasonably well given their total amount spent on payroll? [Use a 95% interval.]

ii. Given their winning percentage, how much would you have expected the Oakland A's to have spent on total payroll? (Use a 95% interval.)

```{r}
# TODO
```


# Multiple Regression

## Auto data set

This question utilizes the `Auto` dataset from ISLR. The original dataset contains 408 observations about cars. It is similar to the CARS dataset that we use in our lectures. To get the data, first install the package ISLR. The `Auto` dataset should be loaded automatically. We'll use this dataset to practice the methods learnt so far. 

You can access the necessary data with the following code:

```{r, eval = T, echo = TRUE}
# Read in the Auto dataset
auto_data <- ISLR::Auto   
```

Get familiar with this dataset first. Tip: you can use the command `?ISLR::Auto` to view a description of the dataset. 

### EDA
Explore the data, with particular focus on pairwise plots and summary statistics. Briefly summarize your findings and any peculiarities in the data.

We will first observe a summary of our data to familiarize ourselves with types and magnitudes. 
```{r results= T}
summary(auto_data)
```
From the `summary`, we can see that most of our variables can be treated as continuous. The exceptions are `origin`, `name` (which is too specific to be significant in our modelling) and arguably `cylinders`, as it is a numerical but discrete variable that can take 6 consecutive integer values. 

To get any insight about the relationships present among our variables, we must produce scatter plots. Note that we are not only interested in the relationship between any independent variable and `MPG`, but in potential relationships among the independent variables, as including highly correlated variables in our model may tamper with significance and produce unreliable coefficients. Spotting linear relationships between variables will allow us to adjust the future model accordingly to avoid multicorrelation and obtain a sound significance level for all of our predictors. 

```{r results = T}
library(ggplot2)
auto_data %>%
  select(mpg, horsepower, weight) %>%
  pairs(main = "MPG, Horsepower & Weight") 

auto_data %>%
  select(mpg, displacement, weight) %>%
  pairs(main = "MPG, Displacement & Weight")

```
From a first glance we see that the variables `displacement`, `horsepower` and `weight` are quite correlated with each other, and theyr scatterplots with mpg have a similar shape. Note that this shape is not precisely linear, but looks like a non-linearly decreasing variable. We may want to avoid including all three of these variables at once. Moreover, we may find productive to apply a transformation to one of these variables in order to obtain a truly linear relation and normal residuals after fitting our model. 

```{r results =T}
auto_data %>%
  select(mpg, acceleration, horsepower) %>%
  pairs(main = "MPG, Acceleration & Horsepower")

auto_data %>%
  select(mpg, cylinders, weight) %>%
  pairs(main = "MPG, Cylinders & Horsepower")

auto_data %>%
  select(mpg, year, horsepower) %>%
  pairs(main = "MPG, Year & Horsepower")

```

Note that acceleration's relationship with `mpg` is weak, and it is correlated with `horsepower`quite significantly, so we might deide to exclude it from the model. The variable `cylinders` shows some peculiarities. Most observations have a `cylinders` value of 4, 6, or 8, so it may be better interpreted as a categorical variable. Finally, note that `year`is uncorrelated with `horsepower`, so including them both in the same model should not cause multicolinearity problems. 

Now, we have noticed that some of our variables seem to have a negative but somewhat non-linear relationship with `mpg`. One of such vaiables is `horsepower`. Thus, we will now explore applying a transformation to `horsepower` and check if the transformed variables displays a more linear relationship with `mpg`. Let us examine the scatterplot in more detail:

```{r results = T}
auto_data %>%
  ggplot(aes(x = horsepower, y = mpg))  +
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(title = "MPG vs HP")
```

At a first glance, the data resembles an exp(-x) function. We will try a logarithmic transformation on `horsepower` an check the scatterplot for improvements:

```{r results = T}
auto_data %>%
  mutate(ln_horsepower = log(horsepower)) %>%
  ggplot(aes(x = ln_horsepower, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(title = "MPG vs ln(HP)")

```

Now the relationship is closer to linear. We may benefit from applying such a transformation to variables like `horsepower` in our final model.

We would also like to explore the relevance of our two categorical variables: `origin` and `cylinders` (interpreted as categorical). To assess different levels of `mpg` across categories, we will plot histograms of `mpg` for each. Note that as very few observations have `cylinders` values of 3 or 5, we will exclude this due to lack of data. 

```{r results = T}
auto_data %>%
  mutate(c_origin = as.factor(origin)) %>%
  ggplot(aes(x = mpg, fill = c_origin)) +
  geom_histogram(binwidth = 2.5) + 
  facet_wrap(~c_origin) + 
  labs(title = "MPG Dist. by Origin")

auto_data %>%
  filter(cylinders %in% c(4, 6, 8)) %>%
  mutate(c_cylinders = as.factor(cylinders)) %>%
  ggplot(aes(x = mpg, fill = c_cylinders)) + 
  geom_histogram(binwidth = 2.5) + 
  facet_wrap(~c_cylinders) + 
  labs(title = "MPG Dist. by #Cylinders")
```

While variation across origins is moderate, level variation based on number of cylinders is clearer. Moreover, variation by origin might explained by other variables. 

### What effect does `time` have on `MPG`?

i. Start with a simple regression of `mpg` vs. `year` and report R's `summary` output. Is `year` a significant variable at the .05 level? State what effect `year` has on `mpg`, if any, according to this model. 

```{r results = T}
fit0 <- lm(mpg ~ year, auto_data)
summary(fit0)
```
The p-value for the coefficient of `year` is very small, capped at 2e-16 < 0.05; thus, `year` is a significant predictor at the 0.05 level. Our interretation of the `year` coefficient is that as it increases by 1, the average `mpg` of cars produced in the year is 1.23 higher. 

ii. Add `horsepower` on top of the variable `year` to your linear model. Is `year` still a significant variable at the .05 level? Give a precise interpretation of the `year`'s effect found here. 
```{r results = T}
fit1 <- lm(mpg ~ horsepower + year, auto_data)
summary(fit1)
```
After adding `horseower`, we confirm that year is still a significant predictor, with a very small p-value that remains far below 0.05. The coefficient of `year`has a different interpretation, as the "partial derivative" of `mpg` with respect to `year`. This means that an increase in `year`  by 1, controlling for `horsepower`, results in an increase of 0.65 in the average car `mpg`. 

iii. The two 95% CI's for the coefficient of year differ among (i) and (ii). How would you explain the difference to a non-statistician?

The CI's for the `year` coefficients are different because fundamentally, these coeffient represent two different concepts. In the simple model, we are in a way assuming we know nothing else about `mpg` apart from its relation to year, and we are using the latter to explain all teh variation in the former. In the multivariate model, we take more information into account, specifically from a second variable `horsepower`, and so we explain variation in `year` using the two, such that the coefficent of `year` only represent the expected change in average `mpg` for a 1-unit increase in `year` but controlling for `horsepower`, that is, assuming no chnage in `horsepower`. This new extra asusmption fundamentally changes the meaning of the coeffient, and thus the model produces a different estimate and CI accordingly.

iv. Create a model with interaction by fitting `lm(mpg ~ year * horsepower)`. Is the interaction effect significant at .05 level? Explain the year effect (if any). 

```{r results = T}
fit2 <- lm(mpg ~ horsepower * year, auto_data)
summary(fit2)
```
All our predictors, including the interaction effect, are statistically significant at the 0.05 level. The year effect, although not as straightforward as before, can still be derived mathematically by taking the partial derivative of our fitted `mpg` with respect to `year`. We can say that as `year` increases by 1, the average `mpg` is expected to increase by 2.19 + -0.016 * `horsepower`, controlling for `horsepower`. 

### Categorical predictors

Remember that the same variable can play different roles! Take a quick look at the variable `cylinders`, and try to use this variable in the following analyses wisely. We all agree that a larger number of cylinders will lower mpg. However, we can interpret `cylinders` as either a continuous (numeric) variable or a categorical variable.

i. Fit a model that treats `cylinders` as a continuous/numeric variable: `lm(mpg ~ horsepower + cylinders, ISLR::Auto)`. Is `cylinders` significant at the 0.01 level? What effect does `cylinders` play in this model?
```{r}
fit3 <- lm(mpg ~ horsepower + cylinders, auto_data)
summary(fit3)
```
The variable `cylinders` is significant at the 0.01 level. In this model, we take `cylinders` as a continuous variable, and so the its effect can be interpreted from the model in line with previous examples: as `cylinders` increases by one unit (as we consider a car with one more cylinder), average `mpg` is expeted to decrease by 1.9198. 

ii. Fit a model that treats `cylinders` as a categorical/factor variable:  `lm(mpg ~ horsepower + as.factor(cylinders), ISLR::Auto)`. Is `cylinders` significant at the .01 level? What is the effect of `cylinders` in this model? Use `anova(fit1, fit2)` and `Anova(fit2)` to help gauge the effect. Explain the difference between `anova()` and `Anova`.
```{r results = T}
fit4 <- lm(mpg ~ horsepower + as.factor(cylinders), auto_data)
summary(fit4)
```
We immediately notice that some category coefficients are not significant. We conduct an F-test to make sure check if `cylinders` as a whole categorical variable is significant. We will do this by producing a reduced model with no `cylinder` categories and comparing it with the full model using the F-statistic.
```{r results = T}
library(car)
fit4_red <- lm(mpg ~ horsepower, auto_data)
anova(fit4_red, fit4)
```
```{r results = T}
Anova(fit4)
```
As the F-test rejects the null, we confirm that `cylinders` is as a whole a statistically significant variables, but the t-test for the coefficient of some categories fails, possibly due to a small number of observations in some categories, as well as multicolinearity-like problems, where some categories of `cylinders` can't offer significant information once other variables are taken into account. 

The effect of `cylinders` has a different interpretation, as it is now discretely divided into 5 categories - note that the category `cylinders = 3` is absorbed in the intercept. For car belonging to a certain category except 3, their average `mpg` is expected to change by the category coefficient, with respect to a car in category 3a and controlling for all other variables in the model.

Regarding to two anovas, `anova()` performs an F-test given a reduced model and a full moedl as inputs. It will only test the significance of the veriables cut from the reduced model together. In contrast, `Anova()` performs an F-test on every variable, effectively revealing if each variable is significant against a reduced model without said variable. In this case, `Anova()` turns out to be more convenient, as we do not need to define a reduced model to obtain our desired F-test. 

Extra: Let's see if we can imporve the categorical `cylinders` model. We will get rid of the 3 and 5 cylinder categories and reproduce the model:
```{r}
auto_data_clean <- auto_data %>% filter(cylinders %in% c(4, 6, 8))
fit5 <- lm(mpg ~ horsepower + as.factor(cylinders), auto_data_clean)
summary(fit5)
```
As we can see, all of our model coefficients are now significant to very precise levels. We will keep this result in mind when producing our final model. 

iii. What are the fundamental differences between treating `cylinders` as a continuous and categorical variable in your models? 

When `cylinders` is treated as a continuous variable, it is explicitly taken as a numeric vector and OLS will output a coefficient for it that will represent the maginal change of the dependent given a one-unit change in `cylinders`. When `cylinders` is taken as categorical, we mean to say that any observation belongs to one category within `cylinders`, and would like to find out whan we can say about observations belonging to each category. The OLS process will first create n-1 dummy variables for n categories, the first one assumed as the base line case and incorporated in our intercept. The vectors of 0's and 1's are then taken as literal numeric vectors and a coefficient is obtained for all n-1 categories. Such a coefficient represents the change (note, with respect to the baseline category) expected on average in the dependent given an observation belongs to a specific category. 

Fundamentally, the implied probability model is also distinct. If we treat `cylinders` as continuous, the probability model implies a linear relationship between the numerical value fo cylinders and the dependent. If `cylinders` is taken as categorical, the model implies observations in each category have a specific mean, which may be distinct from the others. 


### Results

Final modelling question: we want to explore the effects of each feature as best as possible. You may explore interactions, feature transformations, higher order terms, or other strategies within reason. The model(s) should be as parsimonious (simple) as possible unless the gain in accuracy is significant from your point of view.
  
i. Describe the final model. Include diagnostic plots with particular focus on the model residuals and diagnoses.

Our final model regresses `mpg` with respect to `ln(horsepower)`, `year`, `weight`, `year`*`weight` and a categorical variable defined based on cylinders: Less or equal to 4, or greater than 4. Before running the regression, we eliminated observations that had 3 or 5 cylinders, as they were too few to provide reliable information about these levels. 

Below are the model output results:
```{r  echo= T, results= T}
cars <- ISLR::Auto %>% 
  filter(cylinders %in% c(4, 6, 8)) %>% 
  mutate(ln_horsepower = log(horsepower), cyl_cat = cylinders >4)

fit <- lm(mpg ~ ln_horsepower + weight * year + as.factor(cyl_cat), cars)
summary(fit)
  
```
After several trials, this selection of variables and transformations produced a model with high predictive power whose estimated parameters are all statistically significant. We will now include some diagnostics information.
```{r}
fit_data <- data.frame("residuals" = fit$residuals, "fitted" = fit$fitted.values)
fit_data %>%
  ggplot(aes(x = fitted, y = residuals)) + 
  geom_point() + geom_smooth(method = "lm") + 
  labs(title = "Residuals vs Fitted Values Plot")

fit_data %>%
  ggplot(aes(sample = residuals)) + 
  geom_qq() + geom_qq_line()+
  labs(title = "Residual QQ Plot")
```
We confirm that the residuals are centered around 0 and have roughly constant variance across the fitted values, which is a good indicator of independence and homoscedasticity. Moreover, The residual QQ-plot reveals that residuals follow a normal distribution but are somewhat fat-tailed to the right. We plot a histogram of the residuals to confirm this. 

```{r results = T}
fit_data %>%
  ggplot(aes(x = residuals)) + 
  geom_histogram(binwidth = 1)+
  labs(title = "Residual Histogram")
```
Although we understand this is may be a relevant issue, thsi fenomenon was present in almost every other model we tested. Thus, we settle for this model as one of the best performers on the visual normality tests.

ii. Summarize the effects found.

The model coefficients estimate the marginal effects of our independent variables on the dependent `mpg`:

- Horsepower: Our model establishes that the relationship between `horsepower` and `mpg` is not linear, but logarithmic. Using a first approximation for the logarithm, we can say that an increase of 1% in `horsepower` results in a decrease in average `mpg` of -4.37*0.01 = -0.0437.
- Year: We take into account the simple effet and the interaction effect. According to our model, an increase of 1 unit in `year` results in a change in average `mpg` of 1.91 - 0.000443 * `weight`.
- Weight: An increase of 1 unit in `weight` results in a change in average `mpg` of 0.0289 - 0.000443 * year.
- Cylnders: According to our model, cars with more than 4 cylinders have an lower average `mpg` by -2.21 compared to cars with less or eqal to 4 cylinders.
Note: All of these effects are marginal, and must be interpreted as controlling for all other variables in the model. TO avoid redundance, we decided not to specify this fact in the explanation of every effect. 

iii. Predict the `mpg` of the following car: A red car built in the US in 1983 that is 180 inches long, has eight cylinders, displaces 350 cu. inches, weighs 4000 pounds, and has a horsepower of 260. Also give a 95% CI for your prediction.

We create a new car observation following our dataframe structure:
```{r}
cars %>%
  head()

newcar <- cars[1, ]
newcar[1] <- "NA"
newcar[2:5] <- c(8, 350, 260, 4000) 
newcar[6] <- "NA"
newcar[7:8] <- c(83, 1)
newcar[9] <- "NA"
newcar[10] <- log(260)
newcar[11] <- TRUE
newcar
```

Now we will use `predict` to retrieve a prediction for the `mpg` of our new car, and a confidence interval for this prediction:
```{r results = T}
fit.new <- predict(fit, newcar, interval = "prediction", se.fit = TRUE)
fit.new$fit
fit.new$se.fit
fit.new$residual.scale

```

### Appendix

This is code that is roughly equivalent to what we have used earlier but is more streamlined (simulations).

```{r, eval = F, echo = TRUE}
simulate_lm <- function(n) {
  # note: `n` is an input but not used (don't worry about this hack)
  x <- seq(0, 1, length = 40) 
  y <- 1 + 1.2 * x + rnorm(40, sd = 2)
  t_star <- qt(0.975, 38)
  lse <- lm(y ~ x)
  lse_out <- summary(lse)$coefficients
  se <- lse_out[2, 2]
  b1 <- lse_out[2, 1]
  upper_CI = b1 + t_star * se
  lower_CI = b1 - t_star * se
  return(data.frame(se, b1, upper_CI, lower_CI))
}

# this step runs the simulation 100 times, 
# then matrix transposes the result so rows are observations 
sim_results <- data.frame(t(sapply(X = 1:100, FUN = simulate_lm)))
```

